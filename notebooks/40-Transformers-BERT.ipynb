{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Solution - Transformers: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:25:09.684951Z",
     "start_time": "2024-06-14T15:25:09.683017Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:24:33.041886Z",
     "start_time": "2024-06-14T15:24:33.039711Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = '../'\n",
    "DRIVE_PATH = 'Colab/ToxicityClassification'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:24:35.665271Z",
     "start_time": "2024-06-14T15:24:35.093627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register the parent directory of the current script as a package root, \n",
    "# so that we can import modules from the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(ROOT_PATH, 'src')))\n",
    "\n",
    "from toxicity.transformers.bertimbau_base import bert_tokenizer, BertDataset, BertModule\n",
    "from toxicity.transformers.training import train_epochs, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:25:13.340411Z",
     "start_time": "2024-06-14T15:25:13.337992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Target device for running the model\n",
    "PYTORCH_DEVICE = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Random Seed\n",
    "RANDOM_SEED = 777\n",
    "\n",
    "# Training & Validation configs\n",
    "TRAIN_RATIO = 0.8\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-05\n",
    "\n",
    "print(f'Using device: {PYTORCH_DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;5508727285226739644&quot;</td><td>&quot;medo de ir pra um rolê de novo…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16827841903506270139&quot;</td><td>&quot;https://t.co/2bs6oD330q\n",
       "\n",
       "Ele a…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;7641628880024884135&quot;</td><td>&quot;rt USER bruno fernandes assina…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16866242508514532033&quot;</td><td>&quot;tinha que ter jogado esse bran…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;3068271252403811869&quot;</td><td>&quot;eu sou a pessoa certa no bairr…</td><td>[0]</td><td>[0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬──────────────────────┬─────────────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                   ┆ text                            ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                  ┆ ---                             ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                  ┆ str                             ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪══════════════════════╪═════════════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ ToLD-Br ┆ 5508727285226739644  ┆ medo de ir pra um rolê de novo… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 16827841903506270139 ┆ https://t.co/2bs6oD330q         ┆ [0]           ┆ [0]           │\n",
       "│         ┆                      ┆                                 ┆               ┆               │\n",
       "│         ┆                      ┆ Ele a…                          ┆               ┆               │\n",
       "│ ToLD-Br ┆ 7641628880024884135  ┆ rt USER bruno fernandes assina… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 16866242508514532033 ┆ tinha que ter jogado esse bran… ┆ [1]           ┆ [1]           │\n",
       "│ ToLD-Br ┆ 3068271252403811869  ┆ eu sou a pessoa certa no bairr… ┆ [0]           ┆ [0]           │\n",
       "└─────────┴──────────────────────┴─────────────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(os.path.join(ROOT_PATH, 'data', 'joint', 'data.parquet.zstd'))\n",
    "df = df.with_columns(\n",
    "    df['off_relaxed'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    "    df['off_strict'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    ")\n",
    "df.sample(5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;OLID-Br&quot;</td><td>&quot;3d85473d1c4b4f86a78159f23d7746…</td><td>&quot;USER merda, ridículo essa impo…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;OLID-Br&quot;</td><td>&quot;b344c5518f0d44688ed45cc4a3183e…</td><td>&quot;USER espero que eles sejam mor…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;4335543317461660187&quot;</td><td>&quot;eu tenho essas paran贸ias de ac…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;OLID-Br&quot;</td><td>&quot;7ada9be164434f0e925f50616b637c…</td><td>&quot;USER USER é USER USER&quot;</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16784738693255454158&quot;</td><td>&quot;meu pai me deu esse perfume eu…</td><td>[1]</td><td>[0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬────────────────────────────┬───────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                         ┆ text                      ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                        ┆ ---                       ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                        ┆ str                       ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪════════════════════════════╪═══════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ OLID-Br ┆ 3d85473d1c4b4f86a78159f23d ┆ USER merda, ridículo essa ┆ [1]           ┆ [1]           │\n",
       "│         ┆ 7746…                      ┆ impo…                     ┆               ┆               │\n",
       "│ OLID-Br ┆ b344c5518f0d44688ed45cc4a3 ┆ USER espero que eles      ┆ [1]           ┆ [1]           │\n",
       "│         ┆ 183e…                      ┆ sejam mor…                ┆               ┆               │\n",
       "│ ToLD-Br ┆ 4335543317461660187        ┆ eu tenho essas paran贸ias ┆ [0]           ┆ [0]           │\n",
       "│         ┆                            ┆ de ac…                    ┆               ┆               │\n",
       "│ OLID-Br ┆ 7ada9be164434f0e925f50616b ┆ USER USER é USER USER     ┆ [0]           ┆ [0]           │\n",
       "│         ┆ 637c…                      ┆                           ┆               ┆               │\n",
       "│ ToLD-Br ┆ 16784738693255454158       ┆ meu pai me deu esse       ┆ [1]           ┆ [0]           │\n",
       "│         ┆                            ┆ perfume eu…               ┆               ┆               │\n",
       "└─────────┴────────────────────────────┴───────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;10657414299548058873&quot;</td><td>&quot;rt USER mano tá tudo me irrita…</td><td>[1]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;11088205621966361413&quot;</td><td>&quot;USER horrível!&quot;</td><td>[1]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;11546370057009176494&quot;</td><td>&quot;gnt como pode falar q esse hom…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;9450469262872738701&quot;</td><td>&quot;Que foda o USER\n",
       "PUTA QUE PARIU…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16835911729407698751&quot;</td><td>&quot;sapatão é foda, não pode beber…</td><td>[1]</td><td>[1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬──────────────────────┬─────────────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                   ┆ text                            ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                  ┆ ---                             ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                  ┆ str                             ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪══════════════════════╪═════════════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ ToLD-Br ┆ 10657414299548058873 ┆ rt USER mano tá tudo me irrita… ┆ [1]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 11088205621966361413 ┆ USER horrível!                  ┆ [1]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 11546370057009176494 ┆ gnt como pode falar q esse hom… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 9450469262872738701  ┆ Que foda o USER                 ┆ [0]           ┆ [0]           │\n",
       "│         ┆                      ┆ PUTA QUE PARIU…                 ┆               ┆               │\n",
       "│ ToLD-Br ┆ 16835911729407698751 ┆ sapatão é foda, não pode beber… ┆ [1]           ┆ [1]           │\n",
       "└─────────┴──────────────────────┴─────────────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=TRAIN_RATIO, random_state=RANDOM_SEED)\n",
    "display(train_df.head(5))\n",
    "display(test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bert_tokenizer()\n",
    "\n",
    "model = BertModule(feature_count=1)\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "train_loader = DataLoader(BertDataset(data_frame=train_df, tokenizer=tokenizer, max_len=MAX_LEN, target_col='off_relaxed'), shuffle=True,\n",
    "                          num_workers=0, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(BertDataset(data_frame=test_df, tokenizer=tokenizer, max_len=MAX_LEN, target_col='off_relaxed'), shuffle=True,\n",
    "                         num_workers=0, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer\n",
    "\n",
    "Using a Binary Cross Entropy loss as it shows good results for binary classification tasks. We are also applying differente weights to the positive and negative classes to account for the class imbalance and favor the positive class.\n",
    "\n",
    "Adam optimizer is also used as it is a good general optimizer for training neural networks, with good known results for BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "# Heavier weight for the toxic class, to account for favor recall over precision\n",
    "# The ideal pos_weight, if not trying to favor recall should be negative class / positive class\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0], device=PYTORCH_DEVICE))\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe551b78208346e5928e84c9877d4082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 1/5; Average Loss: 0.6547\n",
      "Running training epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94af04f927549f4adacd2986c6aa6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 2/5; Average Loss: 0.5049\n",
      "Running training epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8913d4107644208cb389525888d611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 3/5; Average Loss: 0.3733\n",
      "Running training epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a0cc159f2041f7b578eaf793a1e210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 4/5; Average Loss: 0.2675\n",
      "Running training epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e7aab61bb342739e789ba016a77172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 5/5; Average Loss: 0.1883\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "CHECKPOINT_PATH = os.path.join(ROOT_PATH, 'checkpoints', 'bertimbau', TIMESTAMP)\n",
    "\n",
    "train_epochs(\n",
    "    EPOCHS, model, train_loader, loss_function, optimizer, PYTORCH_DEVICE,\n",
    "    checkpoint_path=CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model_timestamp = int(datetime.now().timestamp())\n",
    "target_dir = f'../models/trained-bertimbau-{model_timestamp}'\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "tokenizer.save_vocabulary(f'{target_dir}')\n",
    "torch.save(model, f'{target_dir}/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf667bd1464f1597fef01d535d9995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate the results\n",
    "raw_results, raw_targets = validate(model, test_loader, PYTORCH_DEVICE)\n",
    "raw_results = np.array(raw_results)\n",
    "raw_targets = np.array(raw_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_THRESHOLD = 0.75\n",
    "fixed_results = raw_results > FIXED_THRESHOLD\n",
    "fixed_targets = raw_targets > FIXED_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics:\n",
      "Weighted F1 = 0.790195\n",
      "Macro F1 = 0.772405\n",
      "Weighted F2 Score = 0.791504\n",
      "Macro F2 Score = 0.768694\n",
      "Accuracy = 0.792881\n",
      "Recall = 0.792881\n",
      "Precision = 0.790131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, fbeta_score, accuracy_score, recall_score, precision_score)\n",
    "\n",
    "fixed_weighted_f1 = f1_score(fixed_targets, fixed_results, average='weighted')\n",
    "fixed_macro_f1 = f1_score(fixed_targets, fixed_results, average='macro')\n",
    "fixed_weighted_f2 = fbeta_score(fixed_targets, fixed_results, beta=2, average='weighted')\n",
    "fixed_macro_f2 = fbeta_score(fixed_targets, fixed_results, beta=2, average='macro')\n",
    "fixed_accuracy = accuracy_score(fixed_targets, fixed_results)\n",
    "fixed_recall = recall_score(fixed_targets, fixed_results, average='weighted')\n",
    "fixed_precision = precision_score(fixed_targets, fixed_results, average='weighted')\n",
    "\n",
    "print(\"Model Metrics:\")\n",
    "print(f\"Weighted F1 = {fixed_weighted_f1:.6f}\")\n",
    "print(f\"Macro F1 = {fixed_macro_f1:.6f}\")\n",
    "print(f\"Weighted F2 Score = {fbeta_score(fixed_targets, fixed_results, beta=2, average='weighted'):.6f}\")\n",
    "print(f\"Macro F2 Score = {fbeta_score(fixed_targets, fixed_results, beta=2, average='macro'):.6f}\")\n",
    "print(f\"Accuracy = {fixed_accuracy:.6f}\")\n",
    "print(f\"Recall = {fixed_recall:.6f}\")\n",
    "print(f\"Precision = {fixed_precision:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
