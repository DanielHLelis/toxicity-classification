{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Solution - Transformers: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:25:09.684951Z",
     "start_time": "2024-06-14T15:25:09.683017Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:24:33.041886Z",
     "start_time": "2024-06-14T15:24:33.039711Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = '../'\n",
    "DRIVE_PATH = 'Colab/ToxicityClassification'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:24:35.665271Z",
     "start_time": "2024-06-14T15:24:35.093627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Register the parent directory of the current script as a package root, \n",
    "# so that we can import modules from the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(ROOT_PATH, 'src')))\n",
    "\n",
    "from toxicity.transformers.bertimbau_base import bert_tokenizer, BertDatasetBF16, BertModuleBF16\n",
    "from toxicity.transformers.training import train_epochs, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:25:13.340411Z",
     "start_time": "2024-06-14T15:25:13.337992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Target device for running the model\n",
    "PYTORCH_DEVICE = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Random Seed\n",
    "RANDOM_SEED = 777\n",
    "\n",
    "# Training & Validation configs\n",
    "TRAIN_RATIO = 0.8\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-05\n",
    "POS_WEIGHT = 1.663\n",
    "\n",
    "print(f'Using device: {PYTORCH_DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;5508727285226739644&quot;</td><td>&quot;medo de ir pra um rolê de novo…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16827841903506270139&quot;</td><td>&quot;https://t.co/2bs6oD330q\n",
       "\n",
       "Ele a…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;7641628880024884135&quot;</td><td>&quot;rt USER bruno fernandes assina…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16866242508514532033&quot;</td><td>&quot;tinha que ter jogado esse bran…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;3068271252403811869&quot;</td><td>&quot;eu sou a pessoa certa no bairr…</td><td>[0]</td><td>[0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬──────────────────────┬─────────────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                   ┆ text                            ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                  ┆ ---                             ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                  ┆ str                             ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪══════════════════════╪═════════════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ ToLD-Br ┆ 5508727285226739644  ┆ medo de ir pra um rolê de novo… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 16827841903506270139 ┆ https://t.co/2bs6oD330q         ┆ [0]           ┆ [0]           │\n",
       "│         ┆                      ┆                                 ┆               ┆               │\n",
       "│         ┆                      ┆ Ele a…                          ┆               ┆               │\n",
       "│ ToLD-Br ┆ 7641628880024884135  ┆ rt USER bruno fernandes assina… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 16866242508514532033 ┆ tinha que ter jogado esse bran… ┆ [1]           ┆ [1]           │\n",
       "│ ToLD-Br ┆ 3068271252403811869  ┆ eu sou a pessoa certa no bairr… ┆ [0]           ┆ [0]           │\n",
       "└─────────┴──────────────────────┴─────────────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(os.path.join(ROOT_PATH, 'data', 'joint', 'data.parquet.zstd'))\n",
    "df = df.with_columns(\n",
    "    df['off_relaxed'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    "    df['off_strict'].cast(pl.Int32).cast(pl.List(pl.Int32)).cast(pl.Array(pl.Int32, 1)),\n",
    ")\n",
    "df.sample(5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;OLID-Br&quot;</td><td>&quot;3d85473d1c4b4f86a78159f23d7746…</td><td>&quot;USER merda, ridículo essa impo…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;OLID-Br&quot;</td><td>&quot;b344c5518f0d44688ed45cc4a3183e…</td><td>&quot;USER espero que eles sejam mor…</td><td>[1]</td><td>[1]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;4335543317461660187&quot;</td><td>&quot;eu tenho essas paran贸ias de ac…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;OLID-Br&quot;</td><td>&quot;7ada9be164434f0e925f50616b637c…</td><td>&quot;USER USER é USER USER&quot;</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16784738693255454158&quot;</td><td>&quot;meu pai me deu esse perfume eu…</td><td>[1]</td><td>[0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬────────────────────────────┬───────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                         ┆ text                      ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                        ┆ ---                       ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                        ┆ str                       ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪════════════════════════════╪═══════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ OLID-Br ┆ 3d85473d1c4b4f86a78159f23d ┆ USER merda, ridículo essa ┆ [1]           ┆ [1]           │\n",
       "│         ┆ 7746…                      ┆ impo…                     ┆               ┆               │\n",
       "│ OLID-Br ┆ b344c5518f0d44688ed45cc4a3 ┆ USER espero que eles      ┆ [1]           ┆ [1]           │\n",
       "│         ┆ 183e…                      ┆ sejam mor…                ┆               ┆               │\n",
       "│ ToLD-Br ┆ 4335543317461660187        ┆ eu tenho essas paran贸ias ┆ [0]           ┆ [0]           │\n",
       "│         ┆                            ┆ de ac…                    ┆               ┆               │\n",
       "│ OLID-Br ┆ 7ada9be164434f0e925f50616b ┆ USER USER é USER USER     ┆ [0]           ┆ [0]           │\n",
       "│         ┆ 637c…                      ┆                           ┆               ┆               │\n",
       "│ ToLD-Br ┆ 16784738693255454158       ┆ meu pai me deu esse       ┆ [1]           ┆ [0]           │\n",
       "│         ┆                            ┆ perfume eu…               ┆               ┆               │\n",
       "└─────────┴────────────────────────────┴───────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>id</th><th>text</th><th>off_strict</th><th>off_relaxed</th></tr><tr><td>str</td><td>str</td><td>str</td><td>array[i32, 1]</td><td>array[i32, 1]</td></tr></thead><tbody><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;10657414299548058873&quot;</td><td>&quot;rt USER mano tá tudo me irrita…</td><td>[1]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;11088205621966361413&quot;</td><td>&quot;USER horrível!&quot;</td><td>[1]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;11546370057009176494&quot;</td><td>&quot;gnt como pode falar q esse hom…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;9450469262872738701&quot;</td><td>&quot;Que foda o USER\n",
       "PUTA QUE PARIU…</td><td>[0]</td><td>[0]</td></tr><tr><td>&quot;ToLD-Br&quot;</td><td>&quot;16835911729407698751&quot;</td><td>&quot;sapatão é foda, não pode beber…</td><td>[1]</td><td>[1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬──────────────────────┬─────────────────────────────────┬───────────────┬───────────────┐\n",
       "│ dataset ┆ id                   ┆ text                            ┆ off_strict    ┆ off_relaxed   │\n",
       "│ ---     ┆ ---                  ┆ ---                             ┆ ---           ┆ ---           │\n",
       "│ str     ┆ str                  ┆ str                             ┆ array[i32, 1] ┆ array[i32, 1] │\n",
       "╞═════════╪══════════════════════╪═════════════════════════════════╪═══════════════╪═══════════════╡\n",
       "│ ToLD-Br ┆ 10657414299548058873 ┆ rt USER mano tá tudo me irrita… ┆ [1]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 11088205621966361413 ┆ USER horrível!                  ┆ [1]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 11546370057009176494 ┆ gnt como pode falar q esse hom… ┆ [0]           ┆ [0]           │\n",
       "│ ToLD-Br ┆ 9450469262872738701  ┆ Que foda o USER                 ┆ [0]           ┆ [0]           │\n",
       "│         ┆                      ┆ PUTA QUE PARIU…                 ┆               ┆               │\n",
       "│ ToLD-Br ┆ 16835911729407698751 ┆ sapatão é foda, não pode beber… ┆ [1]           ┆ [1]           │\n",
       "└─────────┴──────────────────────┴─────────────────────────────────┴───────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=TRAIN_RATIO, random_state=RANDOM_SEED)\n",
    "display(train_df.head(5))\n",
    "display(test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bert_tokenizer()\n",
    "\n",
    "model = BertModuleBF16(feature_count=1)\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "train_loader = DataLoader(BertDatasetBF16(data_frame=train_df, tokenizer=tokenizer, max_len=MAX_LEN, target_col='off_relaxed'), shuffle=True,\n",
    "                          num_workers=0, batch_size=TRAIN_BATCH_SIZE)\n",
    "test_loader = DataLoader(BertDatasetBF16(data_frame=test_df, tokenizer=tokenizer, max_len=MAX_LEN, target_col='off_relaxed'), shuffle=True,\n",
    "                         num_workers=0, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer\n",
    "\n",
    "Using a Binary Cross Entropy loss as it shows good results for binary classification tasks. We are also applying differente weights to the positive and negative classes to account for the class imbalance.\n",
    "\n",
    "Adam optimizer is also used as it is a good general optimizer for training neural networks, with good known results for BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=PYTORCH_DEVICE))\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e6e246cd544405bf2cd431c92efcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training epoch 1/5; Average Loss: 0.6999\n",
      "Running training epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ec6f8f5aa54e04a6b35a35056d0bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m TIMESTAMP \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m CHECKPOINT_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbertimbau\u001b[39m\u001b[38;5;124m'\u001b[39m, TIMESTAMP)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPYTORCH_DEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/USP/Toxicity-Classification/src/toxicity/transformers/training.py:123\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(epoch_count, model, data_loader, loss_fn, optimizer, device, start_epoch, use_tqdm, log_progress, checkpoint_path, autocast, autocast_dtype)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_progress:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning training epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocast_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocast_dtype\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    128\u001b[0m     checkpoint_handler(epoch, avg_loss, checkpoint_path, model, optimizer)\n",
      "File \u001b[0;32m~/Projects/USP/Toxicity-Classification/src/toxicity/transformers/training.py:101\u001b[0m, in \u001b[0;36m_train\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, use_tqdm, autocast, autocast_dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Store Stats\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     epoch_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 101\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m epoch_steps\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "CHECKPOINT_PATH = os.path.join(ROOT_PATH, 'checkpoints', 'bertimbau', TIMESTAMP)\n",
    "\n",
    "train_epochs(\n",
    "    EPOCHS, model, train_loader, loss_function, optimizer, PYTORCH_DEVICE,\n",
    "    checkpoint_path=CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = os.path.join(ROOT_PATH, 'models/trained-bertimbau-{TIMESTAMP}')\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "tokenizer.save_vocabulary(target_dir)\n",
    "torch.save(model, f'{target_dir}/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efa2fd3dbe45eda80a1f9e348f2506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate the results\n",
    "raw_results, raw_targets = validate(model, test_loader, PYTORCH_DEVICE)\n",
    "raw_results = np.array(raw_results)\n",
    "raw_targets = np.array(raw_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_THRESHOLD = 0.75\n",
    "fixed_results = raw_results > FIXED_THRESHOLD\n",
    "fixed_targets = raw_targets > FIXED_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics:\n",
      "Weighted F1 = 0.796040\n",
      "Macro F1 = 0.778208\n",
      "Weighted F2 Score = 0.797554\n",
      "Macro F2 Score = 0.773549\n",
      "Accuracy = 0.799320\n",
      "Recall = 0.799320\n",
      "Precision = 0.796728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, fbeta_score, accuracy_score, recall_score, precision_score)\n",
    "\n",
    "fixed_weighted_f1 = f1_score(fixed_targets, fixed_results, average='weighted')\n",
    "fixed_macro_f1 = f1_score(fixed_targets, fixed_results, average='macro')\n",
    "fixed_weighted_f2 = fbeta_score(fixed_targets, fixed_results, beta=2, average='weighted')\n",
    "fixed_macro_f2 = fbeta_score(fixed_targets, fixed_results, beta=2, average='macro')\n",
    "fixed_accuracy = accuracy_score(fixed_targets, fixed_results)\n",
    "fixed_recall = recall_score(fixed_targets, fixed_results, average='weighted')\n",
    "fixed_precision = precision_score(fixed_targets, fixed_results, average='weighted')\n",
    "\n",
    "print(\"Model Metrics:\")\n",
    "print(f\"Weighted F1 = {fixed_weighted_f1:.6f}\")\n",
    "print(f\"Macro F1 = {fixed_macro_f1:.6f}\")\n",
    "print(f\"Weighted F2 Score = {fbeta_score(fixed_targets, fixed_results, beta=2, average='weighted'):.6f}\")\n",
    "print(f\"Macro F2 Score = {fbeta_score(fixed_targets, fixed_results, beta=2, average='macro'):.6f}\")\n",
    "print(f\"Accuracy = {fixed_accuracy:.6f}\")\n",
    "print(f\"Recall = {fixed_recall:.6f}\")\n",
    "print(f\"Precision = {fixed_precision:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
